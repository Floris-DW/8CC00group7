{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import rdFMCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dced58",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c7b0a",
   "metadata": {},
   "source": [
    "## Load data and compute descriptors & features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51f9d5a0e10b0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tested = pd.read_csv(\"data/tested_molecules.csv\")\n",
    "smiles = tested['SMILES']\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in smiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3607d69",
   "metadata": {},
   "source": [
    "### 2D descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca5b30ca846f1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Descriptors\n",
    "desc_list = [x[0] for x in Descriptors._descList]\n",
    "calc = MoleculeDescriptors.MolecularDescriptorCalculator(desc_list)\n",
    "rdkit_desc = [calc.CalcDescriptors(m) for m in mols]  # our rdkit descriptors: 1116 rows by 210 cols\n",
    "\n",
    "# Create 2d descriptor dataframe\n",
    "desc_names = calc.GetDescriptorNames()\n",
    "df_desc_2d = pd.DataFrame(rdkit_desc, index = smiles, columns=desc_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18069129",
   "metadata": {},
   "source": [
    "### ECFP6 fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adedc5cf830d7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary (Morgan) ECFP6 fingerprints\n",
    "radius = 3  # 2 for similarity exploration, 3 for ML\n",
    "nBits = 1024  # 2048 is default, 1024 is also fine\n",
    "\n",
    "# Calculate binary ECFP6 fingerprints:\n",
    "fingerprints = [AllChem.GetMorganFingerprintAsBitVect(m , radius = radius, nBits = nBits) for m in mols]\n",
    "\n",
    "# Create fingerprint dataframe where each column represents a bit\n",
    "fprint_cols = [f'Bit_{i}' for i in range(1, nBits + 1)]\n",
    "fprint_bits = [list(x) for x in fingerprints]\n",
    "df_fprint = pd.DataFrame(fprint_bits, index = smiles, columns = fprint_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432a55c",
   "metadata": {},
   "source": [
    "### MACCS keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d209dfafba393f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACCS keys\n",
    "maccs_keys = np.array([MACCSkeys.GenMACCSKeys(m) for m in mols])\n",
    "col_name = [f'feature_{i}' for i in range(1, len(maccs_keys[0]) + 1)]\n",
    "\n",
    "# Create MACCS dataframe where each column corresponds to a MACCS feature (structural feature)\n",
    "df_maccs = pd.DataFrame(data = maccs_keys, index = smiles, columns = col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3224dc0",
   "metadata": {},
   "source": [
    "### Molecular Quantum Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbb3d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQNs\n",
    "mqn_ds = [rdMolDescriptors.MQNs_(m) for m in mols]\n",
    "col_name = [f'mqn_{i}' for i in range(1, len(mqn_ds[0]) + 1)]\n",
    "\n",
    "# Create MQN dataframe where each column corresponds to an MQN feature\n",
    "df_mqn = pd.DataFrame(data = mqn_ds, index = smiles, columns = col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5c813",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a36bf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_to_inhibitor_groups(df):\n",
    "    group_00 = df.loc[(df['PKM2_inhibition'] == 0) & (df['ERK2_inhibition'] == 0)]\n",
    "    group_01 = df.loc[(df['PKM2_inhibition'] == 0) & (df['ERK2_inhibition'] == 1)]\n",
    "    group_10 = df.loc[(df['PKM2_inhibition'] == 1) & (df['ERK2_inhibition'] == 0)]\n",
    "    group_11 = df.loc[(df['PKM2_inhibition'] == 1) & (df['ERK2_inhibition'] == 1)]\n",
    "    return group_00, group_01, group_10, group_11\n",
    "\n",
    "def drop_single_value_columns(df, log=False):\n",
    "    new_df = df.copy()\n",
    "    single_value_columns = [col for col in df.columns if len(set(df[col])) == 1]\n",
    "    new_df.drop(single_value_columns, axis=1, inplace=True)\n",
    "    if log:\n",
    "        print(f\"> Dropped {len(single_value_columns)} columns that contain only one value\")\n",
    "    return new_df, single_value_columns\n",
    "\n",
    "def drop_high_correlation_columns(df, threshold=0.9, show=False, log=False):\n",
    "    # Copy df to prevent unwanted changes to original\n",
    "    new_df = df.copy()\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = new_df.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Find features with correlation greater than threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    # Drop features \n",
    "    new_df.drop(to_drop, axis=1, inplace=True)\n",
    "    # Show changes to columns\n",
    "    if log:\n",
    "        print(f\"> Dropped {len(to_drop)} columns of higher than {threshold} correlation\")\n",
    "    # Show old and new correlation matrix\n",
    "    if show:\n",
    "        plt.matshow(df_desc_2d.corr().abs())\n",
    "        plt.matshow(new_df.corr().abs())\n",
    "        plt.show()\n",
    "    \n",
    "    return new_df, to_drop\n",
    "\n",
    "def drop_low_unique_columns(df, tested, nunique_threshold, occurence_threshold, log=False):\n",
    "    # Copy df to prevent unwanted changes to original\n",
    "    new_df = df.copy()\n",
    "    # Collect inhibitor data\n",
    "    group_00, group_01, group_10, group_11 = divide_to_inhibitor_groups(tested)\n",
    "    group_inhibitor = pd.concat([group_01, group_10, group_11], axis=0)\n",
    "    inhibitors = new_df[new_df.index.isin(group_inhibitor[\"SMILES\"])]\n",
    "    # Number of unique values per column\n",
    "    number_uniques_per_column = new_df.nunique()\n",
    "    # Number of non zero values per column\n",
    "    number_non_zero_per_column = new_df.astype(bool).sum(axis=0)\n",
    "    # Determine which features to drop\n",
    "    to_drop = []\n",
    "    for col, num in number_uniques_per_column.items():\n",
    "        # Number of unique values must be below set threshold\n",
    "        if num < nunique_threshold:\n",
    "            # Number of non zero values must be below set threshold\n",
    "            if number_non_zero_per_column[col] < occurence_threshold:\n",
    "                # Don't drop data that describes inhibitors, because the available data is so small already\n",
    "                if inhibitors[col].astype(bool).sum(axis=0) == 0:\n",
    "                    to_drop.append(col)\n",
    "    # Drop features \n",
    "    new_df.drop(to_drop, axis=1, inplace=True)\n",
    "    # Show changes to columns\n",
    "    if log:\n",
    "        print(f\"> Dropped {len(to_drop)} columns of lower than {nunique_threshold} unique entries that occur less than {occurence_threshold} times\")\n",
    "        \n",
    "    return new_df, to_drop\n",
    "\n",
    "def drop_low_variance_columns(df, tested, threshold, log=False):\n",
    "    # Copy df to prevent unwanted changes to original\n",
    "    new_df = df.copy()\n",
    "    # Collect inhibitor data\n",
    "    group_00, group_01, group_10, group_11 = divide_to_inhibitor_groups(tested)\n",
    "    group_inhibitor = pd.concat([group_01, group_10, group_11], axis=0)\n",
    "    inhibitors = df[df.index.isin(group_inhibitor[\"SMILES\"])]\n",
    "    # Determine variance per column\n",
    "    variance_per_column = new_df.var()\n",
    "    # Determine which features to drop\n",
    "    to_drop = []\n",
    "    for col, var in variance_per_column.items():\n",
    "        # print(var)\n",
    "        # Variance must be lower than threshold\n",
    "        if var < threshold:\n",
    "            # Don't drop data that describes inhibitors, because the available data is so small already\n",
    "            if inhibitors[col].astype(bool).sum(axis=0) == 0:\n",
    "                to_drop.append(col)\n",
    "    # Drop features \n",
    "    new_df.drop(to_drop, axis=1, inplace=True)\n",
    "    # Show changes to columns\n",
    "    if log:\n",
    "        print(f\"> Dropped {len(to_drop)} columns of lower than {threshold} variance\")\n",
    "    \n",
    "    return new_df, to_drop\n",
    "\n",
    "def clean_data(df, corr_threshold=0, var_threshold=0, nunique_threshold=0, occurence_threshold=0, show_corr=False, log=True):\n",
    "    new_df = drop_single_value_columns(df, log=log)\n",
    "    if corr_threshold:\n",
    "        new_df = drop_high_correlation_columns(new_df, threshold=corr_threshold, show=show_corr, log=log)\n",
    "    if nunique_threshold and occurence_threshold:\n",
    "        new_df = drop_low_unique_columns(new_df, nunique_threshold=nunique_threshold, occurence_threshold=occurence_threshold, log=log)\n",
    "    if var_threshold:\n",
    "        new_df = drop_low_variance_columns(new_df, threshold=var_threshold, log=log)\n",
    "    print(\"-\" *85, f\"\\nReduced data by {(len(df.columns) - len(new_df.columns)) / len(df.columns)*100:.2f}%: dropped {len(df.columns) - len(new_df.columns)} columns and kept {len(new_df.columns)} columns\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7ac72",
   "metadata": {},
   "source": [
    "### Selecting 2D descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41b253d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Dropped 23 columns that contain only one value\n",
      "> Dropped 59 columns of higher than 0.8 correlation\n",
      "> Dropped 12 columns of lower than 10 unique entries that occur less than 20 times\n",
      "> Dropped 1 columns of lower than 1.0 variance\n",
      "------------------------------------------------------------------------------------- \n",
      "Reduced data by 45.24%: dropped 95 columns and kept 115 columns\n"
     ]
    }
   ],
   "source": [
    "df = df_desc_2d\n",
    "df_orig = df\n",
    "corr_threshold = 0.8\n",
    "var_threshold = 1.0\n",
    "nunique_threshold = 10\n",
    "occurence_threshold = 20\n",
    "show_corr = False\n",
    "log=True\n",
    "desc_2d_dropped_columns = []\n",
    "\n",
    "df, drop_cols = drop_single_value_columns(df, log=log)\n",
    "desc_2d_dropped_columns += drop_cols\n",
    "df, drop_cols = drop_high_correlation_columns(df, threshold=corr_threshold, show=show_corr, log=log)\n",
    "desc_2d_dropped_columns += drop_cols\n",
    "df = pd.DataFrame(MinMaxScaler().fit_transform(df), columns=df.columns, index=df.index)\n",
    "df, drop_cols = drop_low_unique_columns(df, tested=tested, nunique_threshold=nunique_threshold, occurence_threshold=occurence_threshold, log=log)\n",
    "desc_2d_dropped_columns += drop_cols\n",
    "df, drop_cols = drop_low_variance_columns(df, tested=tested, threshold=var_threshold, log=log)\n",
    "print(\"-\" *85, f\"\\nReduced data by {(len(df_orig.columns) - len(df.columns)) / len(df_orig.columns)*100:.2f}%: dropped {len(df_orig.columns) - len(df.columns)} columns and kept {len(df.columns)} columns\")\n",
    "cleaned_desc_2d = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07e14880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "cleaned_desc_2d.to_csv(\"data/cleaned_2d_descriptors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69d61f",
   "metadata": {},
   "source": [
    "### Selecting ECFP6 fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1251118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fprint\n",
    "cleaned_fprint = df.copy()  # Fingerprints need to be kept whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "146c00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "cleaned_fprint.to_csv(\"data/cleaned_fingerprints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba57123",
   "metadata": {},
   "source": [
    "### Selecting MACCS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "845625b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Dropped 24 columns that contain only one value\n",
      "> Dropped 26 columns of higher than 0.8 correlation\n",
      "> Dropped 7 columns of lower than 10 unique entries that occur less than 20 times\n",
      "> Dropped 0 columns of lower than 1.0 variance\n",
      "------------------------------------------------------------------------------------- \n",
      "Reduced data by 34.13%: dropped 57 columns and kept 110 columns\n"
     ]
    }
   ],
   "source": [
    "df = df_maccs\n",
    "df_orig = df\n",
    "corr_threshold = 0.8\n",
    "var_threshold = 1.0\n",
    "nunique_threshold = 10\n",
    "occurence_threshold = 20\n",
    "show_corr = False\n",
    "log=True\n",
    "maccs_dropped_columns = []\n",
    "\n",
    "df, drop_cols = drop_single_value_columns(df, log=log)\n",
    "maccs_dropped_columns += drop_cols\n",
    "df, drop_cols = drop_high_correlation_columns(df, threshold=corr_threshold, show=show_corr, log=log)\n",
    "maccs_dropped_columns += drop_cols\n",
    "df = pd.DataFrame(MinMaxScaler().fit_transform(df), columns=df.columns, index=df.index)\n",
    "df, drop_cols = drop_low_unique_columns(df, tested=tested, nunique_threshold=nunique_threshold, occurence_threshold=occurence_threshold, log=log)\n",
    "maccs_dropped_columns += drop_cols\n",
    "df, drop_cols = drop_low_variance_columns(df, tested=tested, threshold=var_threshold, log=log)\n",
    "print(\"-\" *85, f\"\\nReduced data by {(len(df_orig.columns) - len(df.columns)) / len(df_orig.columns)*100:.2f}%: dropped {len(df_orig.columns) - len(df.columns)} columns and kept {len(df.columns)} columns\")\n",
    "cleaned_maccs = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb86a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "cleaned_maccs.to_csv(\"data/cleaned_maccs_keys.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd4bbf",
   "metadata": {},
   "source": [
    "### Selecting MQN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3d3fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Dropped 4 columns that contain only one value\n",
      "> Dropped 6 columns of higher than 0.8 correlation\n",
      "> Dropped 3 columns of lower than 10 unique entries that occur less than 20 times\n",
      "> Dropped 0 columns of lower than 1.0 variance\n",
      "------------------------------------------------------------------------------------- \n",
      "Reduced data by 30.95%: dropped 13 columns and kept 29 columns\n"
     ]
    }
   ],
   "source": [
    "df = df_mqn\n",
    "df_orig = df\n",
    "corr_threshold = 0.8\n",
    "var_threshold = 1.0\n",
    "nunique_threshold = 10\n",
    "occurence_threshold = 20\n",
    "show_corr = False\n",
    "log=True\n",
    "mqn_dropped_columns = []\n",
    "\n",
    "df, drop_cols = drop_single_value_columns(df, log=log)\n",
    "mqn_dropped_columns += drop_cols\n",
    "df, drop_cols = drop_high_correlation_columns(df, threshold=corr_threshold, show=show_corr, log=log)\n",
    "mqn_dropped_columns += drop_cols\n",
    "df = pd.DataFrame(MinMaxScaler().fit_transform(df), columns=df.columns, index=df.index)\n",
    "df, drop_cols = drop_low_unique_columns(df, tested=tested, nunique_threshold=nunique_threshold, occurence_threshold=occurence_threshold, log=log)\n",
    "mqn_dropped_columns += drop_cols\n",
    "df, drop_cols = drop_low_variance_columns(df, tested=tested, threshold=var_threshold, log=log)\n",
    "print(\"-\" *85, f\"\\nReduced data by {(len(df_orig.columns) - len(df.columns)) / len(df_orig.columns)*100:.2f}%: dropped {len(df_orig.columns) - len(df.columns)} columns and kept {len(df.columns)} columns\")\n",
    "cleaned_mqn = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6aac8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "cleaned_mqn.to_csv(\"data/cleaned_mqn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a4c76",
   "metadata": {},
   "source": [
    "# Untested data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c01df",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0cf646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "untested = pd.read_csv(\"data/untested_molecules-3.csv\")\n",
    "untested_smiles = untested['SMILES']\n",
    "untested_mols = [Chem.MolFromSmiles(smi) for smi in untested_smiles]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963e925",
   "metadata": {},
   "source": [
    "### 2D descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2ce896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Descriptors\n",
    "desc_list = [x[0] for x in Descriptors._descList]\n",
    "calc = MoleculeDescriptors.MolecularDescriptorCalculator(desc_list)\n",
    "rdkit_desc = [calc.CalcDescriptors(m) for m in untested_mols]\n",
    "\n",
    "# Create 2d descriptor dataframe\n",
    "desc_names = calc.GetDescriptorNames()\n",
    "df_desc_2d_untested = pd.DataFrame(rdkit_desc, index=untested_smiles, columns=desc_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24ddad",
   "metadata": {},
   "source": [
    "### ECFP6 fingerprints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56b374ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary (Morgan) ECFP6 fingerprints\n",
    "radius = 3  # 2 for similarity exploration, 3 for ML\n",
    "nBits = 1024  # 2048 is default, 1024 is also fine\n",
    "\n",
    "# Calculate binary ECFP6 fingerprints:\n",
    "fingerprints = [AllChem.GetMorganFingerprintAsBitVect(m , radius = radius, nBits = nBits) for m in untested_mols]\n",
    "\n",
    "# Create fingerprint dataframe where each column represents a bit\n",
    "fprint_cols = [f'Bit_{i}' for i in range(1, nBits + 1)]\n",
    "fprint_bits = [list(x) for x in fingerprints]\n",
    "df_fprint_untested = pd.DataFrame(fprint_bits, index = untested_smiles, columns = fprint_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e703ca",
   "metadata": {},
   "source": [
    "### MACCS keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4580289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACCS keys\n",
    "maccs_keys = np.array([MACCSkeys.GenMACCSKeys(m) for m in untested_mols])\n",
    "col_name = [f'feature_{i}' for i in range(1, len(maccs_keys[0]) + 1)]\n",
    "\n",
    "# Create MACCS dataframe where each column corresponds to a MACCS feature (structural feature)\n",
    "df_maccs_untested = pd.DataFrame(data = maccs_keys, index = untested_smiles, columns = col_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c5d06",
   "metadata": {},
   "source": [
    "### Molecular Quantum Numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1ed9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQNs\n",
    "mqn_ds = [rdMolDescriptors.MQNs_(m) for m in untested_mols]\n",
    "col_name = [f'mqn_{i}' for i in range(1, len(mqn_ds[0]) + 1)]\n",
    "\n",
    "# Create MQN dataframe where each column corresponds to an MQN feature\n",
    "df_mqn_untested = pd.DataFrame(data = mqn_ds, index = untested_smiles, columns = col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98892f44",
   "metadata": {},
   "source": [
    "### Selecting 2D descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d41ac8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_desc_2d_untested.copy()\n",
    "df.drop(desc_2d_dropped_columns, axis=1, inplace=True)\n",
    "untested_desc_2d = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07ed754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "untested_desc_2d.to_csv(\"data/untested_2d_descriptors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78652e65",
   "metadata": {},
   "source": [
    "### Selecting ECFP6 fingerprints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "541a684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "untested_fprint = df_fprint_untested.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15660134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "untested_fprint.to_csv(\"data/untested_fingerprints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5170b5",
   "metadata": {},
   "source": [
    "### Selecting MACCS features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8894aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_maccs_untested.copy()\n",
    "df.drop(maccs_dropped_columns, axis=1, inplace=True)\n",
    "untested_maccs = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69484023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "untested_maccs.to_csv(\"data/untested_maccs_keys.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9234f1c",
   "metadata": {},
   "source": [
    "### Selecting MQN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "982f2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_mqn_untested.copy()\n",
    "df.drop(mqn_dropped_columns, axis=1, inplace=True)\n",
    "untested_mqn = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e2152d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "untested_mqn.to_csv(\"data/untested_mqn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a14243",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35955411",
   "metadata": {},
   "source": [
    "## Testing correlation with inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_fprint, tested, on='SMILES')\n",
    "\n",
    "df = merged_df.copy()\n",
    "single_value_columns = [col for col in df.columns if len(set(df[col])) == 1]\n",
    "df.drop(single_value_columns, axis=1, inplace=True)\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "# print(corr_matrix.iloc[:, -1:])\n",
    "print(max(corr_matrix[\"ERK2_inhibition\"]))\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# Find features with correlation greater than threshold\n",
    "threshold = 0.8\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "# Drop features \n",
    "df.drop(to_drop, axis=1, inplace=True)\n",
    "# Show changes to columns\n",
    "print(f\" Dropped {len(single_value_columns)} single value columns\\n\",\n",
    "      f\"Dropped {len(to_drop)} columns of higher than {threshold} correlation\\n\",\n",
    "      f\"Reduced data by {(len(df_desc_2d.columns) - len(df.columns)) / len(df_desc_2d.columns)*100:.2f}% to {len(df.columns)} columns\")\n",
    "# Show old and new correlation matrix\n",
    "plt.matshow(merged_df.corr().abs().iloc[:, -2:])\n",
    "plt.matshow(df.corr().abs())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396c0d4",
   "metadata": {},
   "source": [
    "## Tanimoto Similarity (ECFP4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ba937",
   "metadata": {},
   "outputs": [],
   "source": [
    "esol_data = tested.copy()\n",
    "\n",
    "ref_smiles = 'O=C(C1CCC1)N1CCc2cc(S(=O)(=O)Nc3ccc4c(c3)OCO4)ccc21'\n",
    "ref_mol = Chem.MolFromSmiles(ref_smiles)\n",
    "ref_ECFP4_fps = AllChem.GetMorganFingerprintAsBitVect(ref_mol,3)\n",
    "\n",
    "PandasTools.AddMoleculeColumnToFrame(esol_data, smilesCol='SMILES')\n",
    "bulk_ECFP4_fps = [AllChem.GetMorganFingerprintAsBitVect(x,3) for x in esol_data['ROMol']]\n",
    "\n",
    "similarity_efcp4 = [DataStructs.FingerprintSimilarity(ref_ECFP4_fps,x) for x in bulk_ECFP4_fps]\n",
    "\n",
    "esol_data['Tanimoto_Similarity (ECFP4)'] = similarity_efcp4\n",
    "# PandasTools.FrameToGridImage(esol_data.head(8), legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)\n",
    "\n",
    "esol_data = esol_data.sort_values(['Tanimoto_Similarity (ECFP4)'], ascending=False)\n",
    "# PandasTools.FrameToGridImage(esol_data.head(8), legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)smiles = group_01[\"SMILES\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fdce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create grid of similarity scores within inhibitor groups\n",
    "def similarity_grid(smiles):\n",
    "    mols = [Chem.MolFromSmiles(smi) for smi in smiles]\n",
    "    df_similarity = pd.DataFrame()\n",
    "\n",
    "    for index, ref_smiles in enumerate(smiles):\n",
    "        ref_mol = mols[index]  # Chem.MolFromSmiles(ref_smiles)\n",
    "        ref_ECFP4_fps = AllChem.GetMorganFingerprintAsBitVect(ref_mol,2)\n",
    "\n",
    "        bulk_ECFP4_fps = [AllChem.GetMorganFingerprintAsBitVect(x,2) for x in mols]\n",
    "\n",
    "        similarity_efcp4 = pd.Series([DataStructs.FingerprintSimilarity(ref_ECFP4_fps,x) for x in bulk_ECFP4_fps])\n",
    "\n",
    "        df_similarity = pd.concat((df_similarity, similarity_efcp4.rename(smiles)), axis=1)\n",
    "    \n",
    "    df_similarity.columns = smiles\n",
    "    df_similarity.index = smiles\n",
    "    plt.matshow(df_similarity)\n",
    "    plt.show()\n",
    "    return df_similarity\n",
    "\n",
    "# df_similarity = similarity_grid(group_01)\n",
    "\n",
    "# Save result\n",
    "# df_similarity.to_csv(\"data/similarity_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity = pd.read_csv(\"data/similarity_10.csv\").set_index(\"SMILES\")\n",
    "max_similarity_per_col = [df_similarity[col].nlargest(2).iloc[1] for col in df_similarity.columns]\n",
    "plt.matshow(df_similarity)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4b4f6",
   "metadata": {},
   "source": [
    "## Most Common Substructure (MCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_00, group_01, group_10, group_11 = divide_to_inhibitor_groups(tested)\n",
    "smiles = group_10[\"SMILES\"]\n",
    "\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in smiles]\n",
    "\n",
    "res = rdFMCS.FindMCS(mols, ringMatchesRingOnly=True)\n",
    "print(res.smartsString)\n",
    "res_mol = Chem.MolFromSmarts(res.smartsString)\n",
    "res_mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_mcs = [mMol.GetSubstructMatch(res_mol) for mMol in mols]\n",
    "Draw.MolsToGridImage(mols, \n",
    "                     highlightAtomLists = highlight_mcs,\n",
    "                     subImgSize=(250,250), useSVG=False, molsPerRow=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
